{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from VAE import *\n",
    "\n",
    "bs = 100\n",
    "# MNIST Dataset\n",
    "class MNISTVideoDataset(Dataset):\n",
    "    def __init__(self, videos):\n",
    "        self.videos = videos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.videos)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video = self.videos[idx]\n",
    "        # Convert video frames to PyTorch tensors\n",
    "        video_tensor = torch.tensor(video, dtype=torch.float32)\n",
    "        return video_tensor\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "train_dataset = MNISTVideoDataset(np.load(\"./image_data/vae_train.npy\"))\n",
    "test_dataset = MNISTVideoDataset(np.load(\"./image_data/vae_test.npy\"))\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "vae = VAE(x_dim=64*64, h_dim1= 256, h_dim2=64, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()\n",
    "optimizer = optim.Adam(vae.parameters(),lr=1e-3)\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 64*64), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "def train(epoch,t=None):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            if t is not None:\n",
    "                t.set_description('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    if t is not None:\n",
    "        t.set_description('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "def test(t=None):\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if t is not None:\n",
    "        t.set_description('====> Test set loss: {:.4f}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "num_epoches=500\n",
    "\n",
    "vae_filename=\"pretrained_vae.pt\"\n",
    "with trange(num_epoches) as t:\n",
    "    for epoch in t:\n",
    "        train(epoch,t)\n",
    "        test(t)\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(64,2 ).cuda()\n",
    "            sample = vae.decoder(z).cuda()\n",
    "            save_image(sample.view(64, 1, 64, 64), f\"./samples/epoch_{epoch}_sample_\" + '.png')\n",
    "torch.save(vae,vae_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display a 2D manifold of the digits\n",
    "n = 20  # figure with 20x20 digits\n",
    "digit_size = 64\n",
    "figure = torch.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "# Construct grid of latent variable values\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "# decode for each square in the grid\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        Z_sample = np.array([[xi, yi]])\n",
    "        Z_sample = torch.tensor(Z_sample,dtype=torch.float32)\n",
    "        Z_sample=Z_sample.cuda()\n",
    "        #print(Z_sample)\n",
    "        \n",
    "        X_decoded = vae.decoder(Z_sample)\n",
    "        digit = X_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] =digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure.detach().numpy(), cmap='gnuplot2')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display a 2D manifold of the digits\n",
    "n = 20  # figure with 20x20 digits\n",
    "digit_size = 64\n",
    "figure = torch.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "# Construct grid of latent variable values\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "# decode for each square in the grid\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        Z_sample = np.array([[xi, yi]])\n",
    "        Z_sample = torch.tensor(Z_sample,dtype=torch.float32)\n",
    "        Z_sample=Z_sample.cuda()\n",
    "        #print(Z_sample)\n",
    "        \n",
    "        X_decoded = vae.decoder(Z_sample)\n",
    "        digit = X_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] =digit\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure.detach().numpy(), cmap='gnuplot2')\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
