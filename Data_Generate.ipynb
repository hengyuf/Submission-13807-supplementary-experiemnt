{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "def create_number_one_image(size, position, figure_width=6):\n",
    "    \"\"\"\n",
    "    Creates an image with a figure of the number '1' at a specified position.\n",
    "    The intensity is highest at the center and decays towards the boundary.\n",
    "    \"\"\"\n",
    "    img = np.zeros(size, dtype=np.float32)\n",
    "    cx, cy = position\n",
    "\n",
    "    # Create a vertical bar in the middle of the image\n",
    "    for x in range(cx - figure_width // 2, cx + figure_width // 2):\n",
    "        for y in range(cy - figure_width // 2, cy + figure_width // 2):\n",
    "            if 0 <= x < size[0] and 0 <= y < size[1]:\n",
    "                img[x, y] = 1.0\n",
    "    \n",
    "    # Apply Gaussian decay for smooth intensity\n",
    "    gaussian =1.3* ndi.gaussian_filter(img, sigma=figure_width / 3.0, mode='constant', cval=0.0)\n",
    "    \n",
    "    # Normalize to range [0, 1]\n",
    "    img = np.clip(gaussian, 0, 1)\n",
    "    \n",
    "    return Image.fromarray((img * 255).astype(np.uint8))\n",
    "\n",
    "def generate_dataset(num_samples, size=(64, 64), figure_width=6):\n",
    "    \"\"\"\n",
    "    Generate a dataset of images with the figure of number '1' at random locations.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for _ in range(num_samples):\n",
    "        x = size[0] // 2+ int(np.clip(np.random.randn()*size[0] // 4,figure_width // 2-size[0]//2  , size[0]//2 - figure_width // 2))\n",
    "        y = size[0] // 2+ int(np.clip(np.random.randn()*size[0] // 4,figure_width // 2-size[0]//2  , size[0]//2 - figure_width // 2))\n",
    "\n",
    "        img = create_number_one_image(size, (x, y), figure_width)\n",
    "        images.append(np.array(img))\n",
    "    return np.array(images)\n",
    "\n",
    "def generate_video_data(num_frames, size=(64, 64), figure_width=10):\n",
    "    \"\"\"\n",
    "    Generate a video dataset with the figure of number '1' moving around.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for _ in range(num_frames):\n",
    "        x = np.random.randint(figure_width // 2, size[0] - figure_width // 2)\n",
    "        y = np.random.randint(0, size[1])\n",
    "        img = create_number_one_image(size, (x, y), figure_width)\n",
    "        frames.append(img)\n",
    "    return np.array(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "train_samples = 20000\n",
    "test_samples = 20000\n",
    "image_size = (64, 64)\n",
    "\n",
    "# Generate and save dataset\n",
    "train_data = generate_dataset(train_samples, size=image_size,figure_width=10)\n",
    "test_data = generate_dataset(test_samples, size=image_size,figure_width=10)\n",
    "\n",
    "# Save datasets as .npy files\n",
    "train_data=train_data.astype('float32').reshape(-1,1,64,64)/255\n",
    "test_data=test_data.astype('float32').reshape(-1,1,64,64)/255\n",
    "np.save('./image_data/vae_train.npy', train_data)\n",
    "np.save('./image_data/vae_test.npy', test_data)\n",
    "\n",
    "print(\"Datasets created and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from numpy import square\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from VAE import VAE\n",
    "num_frames=240\n",
    "num_frame=240\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "def generate_brownian_motion_trajectory(num_frames, size):\n",
    "    \"\"\"\n",
    "    Generate a Brownian motion trajectory for the number '1'.\n",
    "    \"\"\"\n",
    "    # Define Brownian motion parameters\n",
    "    dt = 1  # Time step\n",
    "    sigma = 3  # Volatility (standard deviation of the increments)\n",
    "    \n",
    "    # Generate Brownian motion\n",
    "    increments = np.random.normal(loc=0, scale=sigma * np.sqrt(dt), size=(num_frames, 2))\n",
    "    trajectory = np.cumsum(increments, axis=0)\n",
    "    \n",
    "    # Normalize the trajectory to fit within the image bounds\n",
    "    x_trajectory = np.clip(trajectory[:, 0], -size[0]//2, size[0]//2).astype(int)\n",
    "    y_trajectory = np.clip(trajectory[:, 1],  -size[1]//2, size[1]//2).astype(int)\n",
    "    \n",
    "    return x_trajectory, y_trajectory\n",
    "\n",
    "def generate_brownian_motion_trajectory_batch(num_frames, size,batch_size=1):\n",
    "    \"\"\"\n",
    "    Generate a Brownian motion trajectory for the number '1'.\n",
    "    \"\"\"\n",
    "    # Define Brownian motion parameters\n",
    "    dt = 1  # Time step\n",
    "    sigma = 3  # Volatility (standard deviation of the increments)\n",
    "    \n",
    "    # Generate Brownian motion\n",
    "    increments = np.random.normal(loc=0, scale=sigma * np.sqrt(dt), size=(batch_size, num_frames, 2))\n",
    "    trajectory = np.cumsum(increments, axis=1)\n",
    "    \n",
    "    # Normalize the trajectory to fit within the image bounds\n",
    "    x_trajectory = np.clip(trajectory[:,:, 0], -size[0]//2, size[0]//2-1).astype(int)+size[0]//2\n",
    "    y_trajectory = np.clip(trajectory[:,:, 1],  -size[1]//2, size[1]//2-1).astype(int)+size[1]//2\n",
    "    \n",
    "    return x_trajectory, y_trajectory\n",
    "\n",
    "def generate_bouncing_motion_trajectory(num_frames, size,figure_width=10, speed=2):\n",
    "    \"\"\"\n",
    "    Generate a trajectory where the figure starts at the center and moves towards a random direction,\n",
    "    bouncing back upon reaching the boundary.\n",
    "    \"\"\"\n",
    "    # Start at the center\n",
    "    x, y = 0,0\n",
    "    \n",
    "    # Generate a random direction\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    dx = speed * np.cos(angle)\n",
    "    dy = speed * np.sin(angle)\n",
    "    \n",
    "    x_trajectory = []\n",
    "    y_trajectory = []\n",
    "    \n",
    "    for _ in range(num_frames):\n",
    "        x += dx\n",
    "        y += dy\n",
    "        \n",
    "        # Check for boundary collisions and bounce back if necessary\n",
    "        if x < figure_width//2-size[1]//2 or x >= size[0]//2-figure_width//2:\n",
    "            dx = -dx\n",
    "            x = np.clip(x, figure_width//2-size[0]//2, size[0]//2-figure_width//2 - 1)\n",
    "        \n",
    "        if y < figure_width//2 -size[1]//2 or y >= size[1]//2-figure_width//2:\n",
    "            dy = -dy\n",
    "            y = np.clip(y, figure_width//2-size[1]//2, size[1]//2-figure_width//2 - 1)\n",
    "        \n",
    "        x_trajectory.append(int(x))\n",
    "        y_trajectory.append(int(y))\n",
    "    \n",
    "    return np.array(x_trajectory), np.array(y_trajectory)\n",
    "\n",
    "def generate_figure_8_trajectory(num_frames, size,figure_width, speed=4):\n",
    "    \"\"\"\n",
    "    Generate a figure 8 trajectory with a random starting direction.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, 6 * np.pi, num_frames)\n",
    "    x = np.sin(t)\n",
    "    y = np.sin(2 * t)\n",
    "\n",
    "    # Scale the path to fit within the image bounds\n",
    "    #x = (x - np.min(x)) / (np.max(x) - np.min(x)) * (size[0]/1.2 - 1)\n",
    "    #y = (y - np.min(y)) / (np.max(y) - np.min(y)) * (size[1]/1.2 - 1)\n",
    "\n",
    "    # Rotate the path by a random angle\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    cos_angle = np.cos(angle)\n",
    "    sin_angle = np.sin(angle)\n",
    "\n",
    "    x_rotated = cos_angle * x - sin_angle * y\n",
    "    y_rotated = sin_angle * x + cos_angle * y\n",
    "\n",
    "\n",
    "    # Ensure the trajectory is within bounds\n",
    "    x_trajectory = np.clip(x_rotated*size[0]//np.max(np.abs(x)+np.abs(y))/2,figure_width//2-size[0]//2, size[0]//2-figure_width//2 - 1).astype(int)\n",
    "    y_trajectory = np.clip(y_rotated*size[1]//np.max(np.abs(x)+np.abs(y))/2 ,figure_width//2-size[1]//2, size[1]//2-figure_width//2 - 1).astype(int)\n",
    "\n",
    "    return x_trajectory, y_trajectory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_video_data_batch(num_frames, size=(64, 64), figure_width=3,batch_size=1):\n",
    "    \"\"\"\n",
    "    Generate a video dataset with the figure of number '1' following a Gaussian process trajectory.\n",
    "    \"\"\"\n",
    "    x_trajectory, y_trajectory = generate_brownian_motion_trajectory_batch(num_frames, size,batch_size)\n",
    "\n",
    "    frames=np.zeros((batch_size,num_frames,size[0],size[1]))\n",
    "    for j in tqdm(range(batch_size)):\n",
    "        for i in range(num_frames):\n",
    "            x = x_trajectory[j,i] \n",
    "            y = y_trajectory[j,i]\n",
    "            frames[j,i] = create_number_one_image(size, (x, y), figure_width)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "\n",
    "def generate_video_data(num_frames, size=(64, 64), figure_width=10,motion_type=\"brownian\"):\n",
    "    \"\"\"\n",
    "    Generate a video dataset with the figure of number '1' following a Gaussian process trajectory.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    if motion_type==\"brownian\":\n",
    "        x_trajectory, y_trajectory = generate_brownian_motion_trajectory(num_frames, size)\n",
    "    elif motion_type==\"bounce\":\n",
    "        x_trajectory, y_trajectory = generate_bouncing_motion_trajectory(num_frames, size, figure_width, speed=4)\n",
    "        # plt.plot(x_trajectory, y_trajectory)\n",
    "        # plt.xlim(0,size[0])\n",
    "        # plt.ylim(0,size[1])\n",
    "    elif motion_type==\"8\":\n",
    "        x_trajectory, y_trajectory = generate_figure_8_trajectory(num_frames, size,figure_width, speed=4)\n",
    "    for i in range(num_frames):\n",
    "        x = x_trajectory[i] +size[0]//2\n",
    "        y = y_trajectory[i]+size[1]//2\n",
    "        img = create_number_one_image(size, (x, y), figure_width)\n",
    "        frames.append(img)\n",
    "    \n",
    "    return np.array(frames)\n",
    "\n",
    "def create_number_one_image(size, position, figure_width=6):\n",
    "    \"\"\"\n",
    "    Creates an image with a figure of the number '1' at a specified position.\n",
    "    The intensity is highest at the center and decays towards the boundary.\n",
    "    \"\"\"\n",
    "    img = np.zeros(size, dtype=np.float32)\n",
    "    cx, cy = position\n",
    "\n",
    "    # Create a vertical bar in the middle of the image\n",
    "    for x in range(cx - figure_width // 2, cx + figure_width // 2):\n",
    "        for y in range(cy - figure_width // 2, cy + figure_width // 2):\n",
    "            if 0 <= x < size[0] and 0 <= y < size[1]:\n",
    "                img[x, y] = 1.0\n",
    "    \n",
    "    # Apply Gaussian decay for smooth intensity\n",
    "    gaussian =1.3* ndi.gaussian_filter(img, sigma=figure_width / 3.0, mode='constant', cval=0.0)\n",
    "    \n",
    "    # Normalize to range [0, 1]\n",
    "    img = np.clip(gaussian, 0, 1)\n",
    "    \n",
    "    return Image.fromarray((img * 255).astype(np.uint8))\n",
    "\n",
    "# Function to encode video frames and create a GIF\n",
    "def create_latent_gif(video, vae, gif_filename):\n",
    "    video_tensor = torch.tensor(video, dtype=torch.float32) # Normalize and add channel dimension\n",
    "    \n",
    "    latent_representations = []\n",
    "    with torch.no_grad():\n",
    "        latent,_ = vae.encoder(video_tensor.reshape(num_frames,-1).cuda()) \n",
    "\n",
    "\n",
    "    latent_representations = np.array(latent.cpu())\n",
    "\n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        frame=video[i]\n",
    "        latent=latent_representations[i]\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "        # Plot true image\n",
    "        axs[0].imshow(frame.reshape(64,64))\n",
    "        axs[0].set_title(f'Frame {i}')\n",
    "        axs[0].axis('off')\n",
    "\n",
    "        # Plot latent representation\n",
    "        axs[1].plot(latent_representations[:i, 0], latent_representations[:i, 1], marker='o', linestyle='-', color='b', alpha=0.3)\n",
    "        #axs[1].scatter(latent[0], latent[1], color='r')\n",
    "        axs[1].set_title('Latent Space')\n",
    "        axs[1].set_xlabel('Latent Dimension 1')\n",
    "        axs[1].set_ylabel('Latent Dimension 2')\n",
    "        axs[1].set_xlim(-3,3)\n",
    "        axs[1].set_ylim(-3,3)\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        axs[2].imshow(vae.decoder(torch.tensor(latent.reshape(1,-1)).cuda()).reshape(64,64).detach().cpu())\n",
    "        axs[2].set_title(f'Reconstructed Frame {i}')\n",
    "        axs[2].axis('off')\n",
    "\n",
    "        \n",
    "\n",
    "        # Save the plot as a frame\n",
    "        fig.canvas.draw()\n",
    "        image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "        image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        frames.append(image)\n",
    "\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Create a GIF\n",
    "    imageio.mimsave(gif_filename, frames, format='GIF', duration=0.1)\n",
    "\n",
    "    print(f\"GIF saved as {gif_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size=10000\n",
    "num_frames=240\n",
    "def video_to_latents(video_batch,vae_filename=\"vae_big_ball.pt\"):\n",
    "    vae = VAE(x_dim=64*64, h_dim1= 256, h_dim2=64, z_dim=2)\n",
    "    if torch.cuda.is_available():\n",
    "        vae.cuda()\n",
    "    vae=torch.load(\"./vae_big_ball.pt\")\n",
    "    latents=[]\n",
    "    split=20\n",
    "    for i in tqdm(range(split)):\n",
    "        video_small_batch=np.array(video_batch)[i*batch_size//split:(i+1)*batch_size//split]\n",
    "        \n",
    "        video_tensor = torch.tensor(video_small_batch.astype(\"float32\"))/255 # Normalize and add channel dimension\n",
    "        with torch.no_grad():\n",
    "            latent,_ = vae.encoder(video_tensor.reshape(batch_size//split,num_frames,-1).cuda()) \n",
    "        latents.append(latent.detach().cpu())\n",
    "    return torch.tensor(np.array(latents).reshape(batch_size,num_frames,2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brownian motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:20<00:00, 47.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 240, 64, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_batch=generate_video_data_batch(num_frames, size=(64, 64), figure_width=10,batch_size=1000)\n",
    "video_batch.shape\n",
    "latents=video_to_latents(video_batch,vae_filename=\"vae_big_ball.pt\")\n",
    "torch.save(latents,\"./video_data/latent_data_ball_10_240_brownian.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the covariance matrix of the latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_x=latents[:,:,0]\n",
    "latent_y=latents[:,:,1]\n",
    "plt.title(\"Covariance of latent distribution\")\n",
    "plt.imshow( torch.cov(latent_x.T).detach().cpu())\n",
    "plt.xlabel(\"latent axis 1\")\n",
    "plt.xlabel(\"latent axis 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary bouncing motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 8147/10000 [02:42<00:36, 50.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m video_batch\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(batch_size)):\n\u001b[0;32m----> 3\u001b[0m     video_batch\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgenerate_video_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmotion_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbounce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      4\u001b[0m video_batch\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(video_batch)\n",
      "Cell \u001b[0;32mIn[11], line 163\u001b[0m, in \u001b[0;36mgenerate_video_data\u001b[0;34m(num_frames, size, figure_width, motion_type)\u001b[0m\n\u001b[1;32m    161\u001b[0m     x \u001b[38;5;241m=\u001b[39m x_trajectory[i] \u001b[38;5;241m+\u001b[39msize[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    162\u001b[0m     y \u001b[38;5;241m=\u001b[39m y_trajectory[i]\u001b[38;5;241m+\u001b[39msize[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 163\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_number_one_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_width\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m     frames\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(frames)\n",
      "Cell \u001b[0;32mIn[11], line 183\u001b[0m, in \u001b[0;36mcreate_number_one_image\u001b[0;34m(size, position, figure_width)\u001b[0m\n\u001b[1;32m    180\u001b[0m             img[x, y] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Apply Gaussian decay for smooth intensity\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m gaussian \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.3\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgaussian_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigure_width\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# Normalize to range [0, 1]\u001b[39;00m\n\u001b[1;32m    186\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(gaussian, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/scipy/ndimage/_filters.py:385\u001b[0m, in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate, radius, axes)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(axes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m axis, sigma, order, mode, radius \u001b[38;5;129;01min\u001b[39;00m axes:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mgaussian_filter1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mradius\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/scipy/ndimage/_filters.py:283\u001b[0m, in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate, radius)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# Since we are calling correlate, not convolve, revert the kernel\u001b[39;00m\n\u001b[1;32m    282\u001b[0m weights \u001b[38;5;241m=\u001b[39m _gaussian_kernel1d(sigma, order, lw)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/scipy/ndimage/_filters.py:140\u001b[0m, in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid origin; origin must satisfy \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-(len(weights) // 2) <= origin <= \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(len(weights)-1) // 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    139\u001b[0m mode \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[0;32m--> 140\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m                      \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_batch=[]\n",
    "for i in tqdm(range(batch_size)):\n",
    "    video_batch.append(generate_video_data(num_frames, size=(64, 64), figure_width=10,motion_type=\"bounce\"))\n",
    "video_batch=np.array(video_batch)\n",
    "latents=video_to_latents(video_batch,vae_filename=\"vae_big_ball.pt\")\n",
    "torch.save(latents,\"./video_data/latent_data_ball_10_240_bounce.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_x=latents[:,:,0]\n",
    "latent_y=latents[:,:,1]\n",
    "plt.title(\"Covariance of latent distribution\")\n",
    "plt.imshow( torch.cov(latent_x.T).detach().cpu())\n",
    "plt.xlabel(\"latent axis 1\")\n",
    "plt.xlabel(\"latent axis 2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
